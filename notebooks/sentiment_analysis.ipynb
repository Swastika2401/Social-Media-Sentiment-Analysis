{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ff9e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "438e28f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1 : load the raw data \n",
    "\n",
    "df_modi = pd.read_csv(\"../data/raw/Narendra Modi_data.csv\")\n",
    "df_rahul = pd.read_csv(\"../data/raw/Rahul Gandhi_data.csv\")\n",
    "df_kejriwal = pd.read_csv(\"../data/raw/Arvind Kejriwal_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4be9d761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date             User  \\\n",
      "0  2022:10:19   QuestionsBotYT   \n",
      "1  2022:10:19       PaperDabba   \n",
      "2  2022:10:19   mnjworldcom123   \n",
      "3  2022:10:19  BravePedestrian   \n",
      "4  2022:10:19   NaMoPraveenKor   \n",
      "\n",
      "                                               Tweet      Time  \n",
      "0                        Is Narendra Modi a toaster?  23:57:08  \n",
      "1  5G About To Bring Major Change, Will Revolutio...  23:56:38  \n",
      "2  Prime Minister Shri Narendra Modi along with H...  23:51:02  \n",
      "3  Bharat Mata has waited 5000 years for a true s...  23:40:58  \n",
      "4  How Narendra Modi’s game-changing Gati Shakti ...  23:34:25  \n",
      "         Date             User  \\\n",
      "0  2022:10:19          MdIjran   \n",
      "1  2022:10:19  28bde43dae3c430   \n",
      "2  2022:10:19         SkAnzar5   \n",
      "3  2022:10:19    HariRamDamor2   \n",
      "4  2022:10:19     srinivas_das   \n",
      "\n",
      "                                               Tweet      Time  \n",
      "0  @JaikyYadav16 इन विकल्पों में से और अभी के समय...  23:55:49  \n",
      "1  @ndtv Rahul Gandhi left congress in the mid ro...  23:53:30  \n",
      "2                         @JaikyYadav16 Rahul Gandhi  23:32:16  \n",
      "3             rahul Gandhi ji is real hero of india.  23:32:09  \n",
      "4  Rahul Gandhi is getting massive support in And...  23:21:18  \n",
      "         Date             User  \\\n",
      "0  2022:10:19        bhoo_sene   \n",
      "1  2022:10:19  Madhusu88858324   \n",
      "2  2022:10:19  PremshilaKumarp   \n",
      "3  2022:10:19        lifebecom   \n",
      "4  2022:10:19        sphavisha   \n",
      "\n",
      "                                               Tweet      Time  \n",
      "0  @TajinderBagga Aap leaders are speaking agains...  23:47:01  \n",
      "1  Bjp Aap se sikh rhi h\\nNarendra Modi Manish Si...  23:06:35  \n",
      "2                      @JaikyYadav16 Arvind kejriwal  22:56:42  \n",
      "3  Arvind Kejriwal As PM Visits Gujarat School ht...  22:20:51  \n",
      "4  Arvind Kejriwal's stand against rape is very c...  22:20:16  \n"
     ]
    }
   ],
   "source": [
    "print(modi_df.head())\n",
    "print(rahul_df.head())\n",
    "print(kejri_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5978e563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Data Loaded. Total rows: 210000\n"
     ]
    }
   ],
   "source": [
    "# combine dataframes\n",
    "df = pd.concat([df_modi, df_rahul, df_kejriwal], ignore_index=True)\n",
    "print(\"Combined Data Loaded. Total rows:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80e88fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP -2 initial preprocessing (cleaning the text)\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text= str(text) # to make sure text is string \n",
    "    text=re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text) # Remove mentions (@anurag)\n",
    "    text = re.sub(r'RT[\\s]+', '', text) # Remove Retweet tags\n",
    "    text = re.sub(r'[^\\w\\s#]', '', text) # Remove special characters/emojis\n",
    "    text = text.lower() # Convert to lowercase\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e199daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_Tweet'] = df['Tweet'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6938c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets Cleaned\n"
     ]
    }
   ],
   "source": [
    "df.dropna(subset=['Clean_Tweet'] , inplace=True) # Important : Drop not a number values\n",
    "print(\"Tweets Cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d008ec",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4775714b",
   "metadata": {},
   "source": [
    "## STEP 3: labeling the Data(Heuristic/Rule-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acc5628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_keywords = ['hero', 'great', 'proud', 'massive support', 'game-changing', 'achievement', 'optimism', 'exciting', 'interesting']\n",
    "negative_keywords = ['dead horse', 'blunt sword', 'fascism', 'venom', 'against', 'hiding', 'sikh rhi h', 'sikh rhe h', 'fools', 'toaster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4089ac2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Label Distribution (Target Variable):\n",
      "Sentiment_Label\n",
      " 0    199231\n",
      " 1      6681\n",
      "-1      4088\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "positive_keywords = ['hero', 'great', 'proud', 'massive support', 'game-changing', 'achievement', 'optimism', 'exciting', 'interesting']\n",
    "negative_keywords = ['dead horse', 'blunt sword', 'fascism', 'venom', 'against', 'hiding', 'sikh rhi h', 'sikh rhe h', 'fools', 'toaster']\n",
    "\n",
    "def simple_labeler(text):\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    if any(keyword in text_lower for keyword in negative_keywords):\n",
    "        return -1 # means negative\n",
    "    \n",
    "    if any(keyword in text_lower for keyword in positive_keywords):\n",
    "        return 1 # means positive\n",
    "    \n",
    "    return 0 # means neutral\n",
    "\n",
    "df['Sentiment_Label'] = df['Clean_Tweet'].apply(simple_labeler)\n",
    "\n",
    "print(\"\\nSentiment Label Distribution (Target Variable):\")\n",
    "print(df['Sentiment_Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ee19cd",
   "metadata": {},
   "source": [
    "## STEP 4: Feature Engineering (TF-IDF Vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "041c1f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data shape after TF-IDF: (168000, 128334)\n",
      "Testing data shape after TF-IDF: (42000, 128334)\n"
     ]
    }
   ],
   "source": [
    "# separate features(x) and target(y)\n",
    "\n",
    "X = df['Clean_Tweet']\n",
    "Y = df['Sentiment_Label']\n",
    "\n",
    "# split data into training and testing sets(80% train and 20% test )\n",
    "# stratify=y ensures the train/test split has the same ratio of sentiment labels\n",
    "\n",
    "X_train , X_test , Y_train , Y_test = train_test_split(X, Y , test_size=0.2, random_state=42, stratify=Y)\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8, min_df=1)\n",
    "\n",
    "# Fit/Train the vectorizer on the training data and transform both sets\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"\\nTraining data shape after TF-IDF: {X_train_tfidf.shape}\")\n",
    "print(f\"Testing data shape after TF-IDF: {X_test_tfidf.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3239abb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
