{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff9e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "438e28f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1 : load the raw data \n",
    "\n",
    "df_modi = pd.read_csv(\"../data/raw/Narendra Modi_data.csv\")\n",
    "df_rahul = pd.read_csv(\"../data/raw/Rahul Gandhi_data.csv\")\n",
    "df_kejriwal = pd.read_csv(\"../data/raw/Arvind Kejriwal_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4be9d761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date             User  \\\n",
      "0  2022:10:19   QuestionsBotYT   \n",
      "1  2022:10:19       PaperDabba   \n",
      "2  2022:10:19   mnjworldcom123   \n",
      "3  2022:10:19  BravePedestrian   \n",
      "4  2022:10:19   NaMoPraveenKor   \n",
      "\n",
      "                                               Tweet      Time  \n",
      "0                        Is Narendra Modi a toaster?  23:57:08  \n",
      "1  5G About To Bring Major Change, Will Revolutio...  23:56:38  \n",
      "2  Prime Minister Shri Narendra Modi along with H...  23:51:02  \n",
      "3  Bharat Mata has waited 5000 years for a true s...  23:40:58  \n",
      "4  How Narendra Modi’s game-changing Gati Shakti ...  23:34:25  \n",
      "         Date             User  \\\n",
      "0  2022:10:19        bhoo_sene   \n",
      "1  2022:10:19  Madhusu88858324   \n",
      "2  2022:10:19  PremshilaKumarp   \n",
      "3  2022:10:19        lifebecom   \n",
      "4  2022:10:19        sphavisha   \n",
      "\n",
      "                                               Tweet      Time  \n",
      "0  @TajinderBagga Aap leaders are speaking agains...  23:47:01  \n",
      "1  Bjp Aap se sikh rhi h\\nNarendra Modi Manish Si...  23:06:35  \n",
      "2                      @JaikyYadav16 Arvind kejriwal  22:56:42  \n",
      "3  Arvind Kejriwal As PM Visits Gujarat School ht...  22:20:51  \n",
      "4  Arvind Kejriwal's stand against rape is very c...  22:20:16  \n",
      "         Date             User  \\\n",
      "0  2022:10:19          MdIjran   \n",
      "1  2022:10:19  28bde43dae3c430   \n",
      "2  2022:10:19         SkAnzar5   \n",
      "3  2022:10:19    HariRamDamor2   \n",
      "4  2022:10:19     srinivas_das   \n",
      "\n",
      "                                               Tweet      Time  \n",
      "0  @JaikyYadav16 इन विकल्पों में से और अभी के समय...  23:55:49  \n",
      "1  @ndtv Rahul Gandhi left congress in the mid ro...  23:53:30  \n",
      "2                         @JaikyYadav16 Rahul Gandhi  23:32:16  \n",
      "3             rahul Gandhi ji is real hero of india.  23:32:09  \n",
      "4  Rahul Gandhi is getting massive support in And...  23:21:18  \n"
     ]
    }
   ],
   "source": [
    "print(df_modi.head())\n",
    "print(df_kejriwal.head())\n",
    "print(df_rahul.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5978e563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Data Loaded. Total rows: 210000\n"
     ]
    }
   ],
   "source": [
    "# combine dataframes\n",
    "df = pd.concat([df_modi, df_rahul, df_kejriwal], ignore_index=True)\n",
    "print(\"Combined Data Loaded. Total rows:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e88fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP -2 initial preprocessing (cleaning the text)\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text= str(text) # to make sure text is string \n",
    "    text=re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text) # Remove mentions (@anurag)\n",
    "    text = re.sub(r'RT[\\s]+', '', text) # Remove Retweet tags\n",
    "    text = re.sub(r'[^\\w\\s#]', '', text) # Remove special characters/emojis\n",
    "    text = text.lower() # Convert to lowercase\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e199daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_Tweet'] = df['Tweet'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6938c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets Cleaned\n"
     ]
    }
   ],
   "source": [
    "df.dropna(subset=['Clean_Tweet'] , inplace=True) # Important : Drop not a number values\n",
    "print(\"Tweets Cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d008ec",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4775714b",
   "metadata": {},
   "source": [
    "## STEP 3: labeling the Data(Heuristic/Rule-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acc5628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_keywords = [\n",
    "    'hero', 'great', 'proud', 'massive support', 'game-changing', \n",
    "    'achievement', 'optimism', 'exciting', 'interesting',\n",
    "    'awesome', 'amazing', 'fantastic', 'wonderful', 'brilliant', 'excellent',\n",
    "    'impressive', 'outstanding', 'incredible', 'beautiful', 'love',\n",
    "    'respect', 'support', 'well done', 'congrats', 'congratulations',\n",
    "    'victory', 'win', 'successful', 'superb', 'legend', 'epic', 'cool',\n",
    "    'positive', 'grateful', 'thankful', 'encouraging', 'celebrate', \n",
    "    'inspiring', 'inspiration', 'remarkable', 'top notch', 'thrilled',\n",
    "    'great job', 'kudos', 'heartwarming', 'uplifting', 'blessed',\n",
    "    'good vibes', 'happy', 'joy', 'delight', 'cheerful', 'excellent work',\n",
    "    'well deserved', 'improvement', 'progress', 'milestone',\n",
    "    'mast', 'badiya', 'zabardast', 'solid', 'kamaal', 'dil jeet' 'liya', 'shandar',\n",
    "'respect mil gaya', 'pyaar', 'dhamaal', 'sahi hai',' proud moment'\n",
    "\n",
    "]\n",
    "\n",
    "negative_keywords = [\n",
    "    'dead horse', 'blunt sword', 'fascism', 'venom', 'against', 'hiding',\n",
    "    'sikh rhi h', 'sikh rhe h', 'fools', 'toaster',\n",
    "    'hate', 'terrible', 'awful', 'worst', 'bad', 'disaster', 'fail', 'failure',\n",
    "    'useless', 'nonsense', 'trash', 'pathetic', 'angry', 'annoying',\n",
    "    'ridiculous', 'joke', 'mess', 'broken', 'problem', 'issue', 'disappointing',\n",
    "    'weak', 'corrupt', 'shame', 'shameful', 'stupid', 'idiot', 'nasty',\n",
    "    'negative', 'toxic', 'boring', 'lame', 'sucks', 'cringe', 'misery',\n",
    "    'frustrating', 'horrible', 'tragic', 'dangerous', 'pain', 'suffering',\n",
    "    'warning', 'complaint', 'attack', 'blame', 'exposed', 'failure', 'fraud',\n",
    "    'lies', 'liar', 'broken', 'problematic','bakwas', 'bekaar', 'chutiya', 'ghatiya', 'faltu', 'chutiyapa', 'pagal', 'bewakoof',\n",
    "'fraud', 'dhokha', 'khooti baat,'  , 'lafda', 'pareshan', 'beizzati', 'gussa'\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4089ac2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Label Distribution (Target Variable):\n",
      "Sentiment_Label\n",
      " 0    147942\n",
      " 1     33782\n",
      "-1     28276\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def simple_labeler(text):\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    if any(keyword in text_lower for keyword in negative_keywords):\n",
    "        return -1 # means negative\n",
    "    \n",
    "    if any(keyword in text_lower for keyword in positive_keywords):\n",
    "        return 1 # means positive\n",
    "    \n",
    "    return 0 # means neutral\n",
    "\n",
    "df['Sentiment_Label'] = df['Clean_Tweet'].apply(simple_labeler)\n",
    "\n",
    "print(\"\\nSentiment Label Distribution (Target Variable):\")\n",
    "print(df['Sentiment_Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ee19cd",
   "metadata": {},
   "source": [
    "## STEP 4: Feature Engineering (TF-IDF Vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "041c1f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data shape after TF-IDF: (168000, 128439)\n",
      "Testing data shape after TF-IDF: (42000, 128439)\n"
     ]
    }
   ],
   "source": [
    "# separate features(x) and target(y)\n",
    "\n",
    "X = df['Clean_Tweet']\n",
    "Y = df['Sentiment_Label']\n",
    "\n",
    "# split data into training and testing sets(80% train and 20% test )\n",
    "# stratify=y ensures the train/test split has the same ratio of sentiment labels\n",
    "\n",
    "X_train , X_test , Y_train , Y_test = train_test_split(X, Y , test_size=0.2, random_state=42, stratify=Y)\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8, min_df=1)\n",
    "\n",
    "# Fit/Train the vectorizer on the training data and transform both sets\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"\\nTraining data shape after TF-IDF: {X_train_tfidf.shape}\")\n",
    "print(f\"Testing data shape after TF-IDF: {X_test_tfidf.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3239abb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anurag/Desktop/CODE/Social-Media-Sentiment-Analysis/.venv/lib64/python3.14/site-packages/sklearn/linear_model/_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/anurag/Desktop/CODE/Social-Media-Sentiment-Analysis/.venv/lib64/python3.14/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n",
      "\n",
      " model evaluation results\n",
      "Overall Accuracy: 0.9407\n",
      "\n",
      " Classification Report (Precision, Recall, F1-Score) \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Negative (-1)       0.99      0.72      0.83      5655\n",
      "  Neutral (0)       0.93      1.00      0.96     29589\n",
      " Positive (1)       0.97      0.87      0.92      6756\n",
      "\n",
      "     accuracy                           0.94     42000\n",
      "    macro avg       0.96      0.86      0.90     42000\n",
      " weighted avg       0.94      0.94      0.94     42000\n",
      "\n",
      "\n",
      " Confusion Matrix (Actual vs. Predicted) \n",
      " \n",
      " Predicted: -1    0    1 \n",
      " \n",
      "Actual -1: [4077 1384  194]\n",
      "Actual 0:  [   24 29564     1]\n",
      "Actual 1:  [  10  879 5867]\n"
     ]
    }
   ],
   "source": [
    "# model training and eveluation\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import confusion_matrix , classification_report ,accuracy_score \n",
    "import numpy as np \n",
    "\n",
    "logreg_model = LogisticRegression(\n",
    "    solver='liblinear', \n",
    "    random_state=42, \n",
    "    multi_class='ovr', \n",
    "    max_iter=1000 # Increased max_iter for convergence\n",
    ")\n",
    "\n",
    "print(\"\\n Starting model training...\")\n",
    "logreg_model.fit(X_train_tfidf , Y_train )\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# make predictions on test-set\n",
    "Y_pred = logreg_model.predict(X_test_tfidf)\n",
    "\n",
    "#model evalution\n",
    "print(\"\\n model evaluation results\")\n",
    "\n",
    "overall_accuracy = accuracy_score(Y_test , Y_pred)\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "\n",
    " #  Classification Report (Detailed performance per class)\n",
    "\n",
    "print(\"\\n Classification Report (Precision, Recall, F1-Score) \")\n",
    "print(classification_report(Y_test, Y_pred, target_names=['Negative (-1)', 'Neutral (0)', 'Positive (1)']))\n",
    "\n",
    "\n",
    "#  Confusion Matrix\n",
    "# it will show -->  how many instances were correctly and incorrectly classified for each class\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "print(\"\\n Confusion Matrix (Actual vs. Predicted) \")\n",
    "\n",
    "# Labels: Actual on rows, Predicted on columns\n",
    "# [[TN, FP_to_0, FP_to_1]\n",
    "#  [FN_to_-1, TN_0, FP_to_1]\n",
    "#  [FN_to_-1, FN_to_0, TP]]\n",
    "print(\" \\n Predicted: -1    0    1 \\n \")\n",
    "print(f\"Actual -1: {conf_matrix[0]}\")\n",
    "print(f\"Actual 0:  {conf_matrix[1]}\")\n",
    "print(f\"Actual 1:  {conf_matrix[2]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1471659b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c8a836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
